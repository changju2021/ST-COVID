{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bb1e0a-4b64-4288-8282-bfa89ecab86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "len_train =80 \n",
    "'''\n",
    "Min-Max Scaler\n",
    "展平所有特征，进行放缩\n",
    "'''\n",
    "class MyMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.xmin,self.xmax = None,None\n",
    "    def fit_transform(self,train):\n",
    "        self.xmin,self.xmax = np.min(train),np.max(train)\n",
    "        return self.transform(train)\n",
    "    def transform(self,x):\n",
    "        return (x-self.xmin)/(self.xmax-self.xmin)\n",
    "    def inverse_transform(self,t):\n",
    "        return t*(self.xmax-self.xmin)+self.xmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15165e9-ffcd-477f-a8c4-e14ec04de645",
   "metadata": {},
   "source": [
    "## 预处理（运行一次）\n",
    "+ 截取时间\n",
    "+ 检查county是否一致，是否每个county的天数是满的 (删去44007)\n",
    "+ 缺失值检查\n",
    "+ 数据集120 days (80:20:20)\n",
    "+ 75个county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ced30a-759a-49d7-b909-7c9dcd808146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "(9075, 6)\n",
      "75\n",
      "(9000, 8)\n",
      "75\n",
      "(9000, 6)\n",
      "(75, 7)\n"
     ]
    }
   ],
   "source": [
    "start, end = \"2020-03-22\",\"2020-07-20\"\n",
    "for fn in ['cases.csv','mobility.csv','range.csv']:\n",
    "    df = pd.read_csv(fn)\n",
    "    if fn == 'cases.csv':\n",
    "        df = df[(df.date>=start)&(df.date<=end)]\n",
    "    else:\n",
    "        df = df[(df.date>start)&(df.date<=end)]\n",
    "    df.sort_values(['fips','date'],inplace=True)\n",
    "    print(len(df.fips.unique()))\n",
    "    print(df.shape)\n",
    "    df.to_csv(fn,index=None)\n",
    "df =pd.read_csv('static.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb5c4b7-b070-40df-82b9-c1032245503f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9075, 6)\n",
      "(9000, 8)\n",
      "(9000, 6)\n",
      "(75, 7)\n"
     ]
    }
   ],
   "source": [
    "fips = pd.read_csv('mobility.csv')['fips'].unique()\n",
    "cases = pd.read_csv('cases.csv')\n",
    "for fip in fips:\n",
    "    if cases[cases.fips==fip].shape[0]<120:\n",
    "        print(fip)\n",
    "for fn in ['cases.csv','mobility.csv','range.csv','static.csv']:\n",
    "    df = pd.read_csv(fn)\n",
    "    df = df[(df.fips!=44007)]\n",
    "    print(df.shape)\n",
    "    df.to_csv(fn,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdc40f-3488-4068-89d3-ce1f18dd5da2",
   "metadata": {},
   "source": [
    "## static特征\n",
    "+ (75, 77) = (75个county,75距离+1人口密度+1人口数)\n",
    "+ 对前75维，后面两维分别进行MinMaxScaler(MyMinMaxScaler和sklearn的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c9cfed-dabe-481c-ad5d-1579342c7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/scipy/spatial/distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('static.csv')\n",
    "# df.sort_values(by=['fips'],inplace=True)\n",
    "# n = df.shape[0]\n",
    "# xs = np.zeros((n,n+2))\n",
    "# lat,long = df['lat'].values,df['long'].values\n",
    "# pop = df[['pop_density', 'tot_pop']].values\n",
    "# for i in range(n):\n",
    "#     for j in range(n):\n",
    "#         if i==j:\n",
    "#             continue\n",
    "#         else:\n",
    "#             xs[i,j] = haversine((lat[i],long[i]),(lat[j],long[j]),'km')\n",
    "# xs[:,n:] = pop\n",
    "\n",
    "# skscaler = MinMaxScaler()\n",
    "# xs = skscaler.fit_transform(xs)\n",
    "# xs.shape\n",
    "\n",
    "\n",
    "df = pd.read_csv('static.csv')\n",
    "df.sort_values(by=['fips'],inplace=True)\n",
    "n = df.shape[0]\n",
    "xs = np.zeros((n,n,2))\n",
    "lat,long = df['lat'].values,df['long'].values\n",
    "scaler = MinMaxScaler()\n",
    "pop = scaler.fit_transform(df[['pop_density', 'tot_pop']].values)\n",
    "print(pop.shape)\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "\n",
    "        xs[i,j,0] = haversine((lat[i],long[i]),(lat[j],long[j]),'km')\n",
    "        xs[j,i,0] = xs[i,j,0]\n",
    "\n",
    "        xs[i,j,1] = 1 - spatial.distance.cosine(pop[i,:], pop[j,:])\n",
    "        # print(i,j,result)\n",
    "        xs[j,i,1] = xs[i,j,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc1703-3c3c-49b1-b43d-480ca5c99a61",
   "metadata": {},
   "source": [
    "## 感染人数相关特征\n",
    "+ (75,120,6) = (county,time_length,features_dim)\n",
    "+ 累积确诊、累积死亡、新增确诊、新增死亡、新增确诊/累积确诊、新增死亡/累积死亡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b866d886-83ef-4b62-9879-320ffaee8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 121, 6)\n",
      "(75, 120, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cases.csv')\n",
    "df.sort_values(by=['fips','date'],inplace=True)\n",
    "fips = df['fips'].unique()\n",
    "n,l = len(fips), int(df.shape[0]/len(fips))\n",
    "xi = np.zeros((n,l,6))\n",
    "\n",
    "### Acc_Cases\n",
    "for i,fip in enumerate(fips):\n",
    "    xi[i,:,0] = df[df.fips==fip]['cases'].values\n",
    "    xi[i,:,1] = df[df.fips==fip]['deaths'].values\n",
    "    \n",
    "xi[:,1:,2] = xi[:,1:,0]-xi[:,:-1,0]\n",
    "\n",
    "xi[:,1:,3] = xi[:,1:,1]-xi[:,:-1,1]\n",
    "\n",
    "xi[:,:,4] = xi[:,:,2] / xi[:,:,0]\n",
    "\n",
    "mask = (xi[:,:,1]!=0)\n",
    "xi[mask,5] = xi[mask,3] / xi[mask,1]\n",
    "\n",
    "print(xi.shape)\n",
    "xi = xi[:,1:,:]\n",
    "print(xi.shape)\n",
    "\n",
    "\n",
    "### 保存xi[:,:,2]的scaler\n",
    "for i in range(6):\n",
    "    scaler = MyMinMaxScaler()\n",
    "    xi[:,:len_train,i] = scaler.fit_transform(xi[:,:len_train,i])\n",
    "    xi[:,len_train:,i] = scaler.transform(xi[:,len_train:,i])\n",
    "    # if i==0:\n",
    "    #     f = open('acc_scaler.pickle','wb')\n",
    "    #     pickle.dump(scaler, f)\n",
    "    #     f.close()\n",
    "    if i==2:\n",
    "        f = open('scaler.pickle','wb')\n",
    "        pickle.dump(scaler, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d39ce-01de-459a-af62-9c666f8e81dd",
   "metadata": {},
   "source": [
    "## mobilty and movement range\n",
    "+ (75,120,8)\n",
    "+ 6 mobility+2 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1a087d-213d-4978-a5cc-274ceb6cfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mob = pd.read_csv('mobility.csv')\n",
    "mob.sort_values(by=['fips','date'],inplace=True)\n",
    "move = pd.read_csv('range.csv')\n",
    "move.sort_values(by=['fips','date'],inplace=True)\n",
    "\n",
    "fips = mob['fips'].unique()\n",
    "xm = np.zeros((len(fips),int(mob.shape[0]/len(fips)),8))\n",
    "\n",
    "for i,fip in enumerate(fips):\n",
    "    xm[i,:,:6] = mob[mob.fips==fip][['f1','f2','f3','f4','f5','f6']].values\n",
    "    xm[i,:,6:] = move[move.fips==fip][['f1','f2']].values\n",
    "\n",
    "for i in range(6): \n",
    "    scaler = MyMinMaxScaler()\n",
    "    xm[:,:len_train,i] = scaler.fit_transform(xm[:,:len_train,i])\n",
    "    xm[:,len_train:,i] = scaler.fit_transform(xm[:,len_train:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81a55e-f916-47e8-a03c-05208ea76357",
   "metadata": {},
   "source": [
    "## 封装成pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be36dd79-6eff-4eae-9c84-7f095047df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'xs':xs,'xm':xm,'xi':xi}\n",
    "f = open('features.pickle','wb')\n",
    "pickle.dump(features, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34841379-105e-477c-84c6-05310a0c9210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
