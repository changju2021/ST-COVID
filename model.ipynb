{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bf0a2f-dfc7-4a62-abf0-a5b60064ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as spp\n",
    "import dgl\n",
    "from dgl.nn import EdgeWeightNorm, GraphConv\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    \n",
    "P = 10\n",
    "Q = 5\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"US_State/v1/\"\n",
    "model_path = data_path+\"mdl3/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "save_path = model_path+\"mdl3_%d.pt\"%(P)\n",
    "\n",
    "\n",
    "f = open(data_path+\"scaler.pickle\",\"rb\")\n",
    "scaler = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_path+\"features.pickle\",\"rb\")\n",
    "features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "len_train, len_val = 80, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9c9367-b405-4f76-a705-97413b76a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAANgklEQVR4nO3de4xcdRnG8eeRQiqggHa1CNSpaGjRgpBFAYUA1QSRWIxNiiIiYho04CUYWf/RTYyBP8SgpkqaeqlKRAKohAUv6WLEcIlbKNcFQUQoF7teAt6h+vrHzNbtdnfn7DlnZvbtfj/JZmfOnJnf+86ZfXp6Zs78HBECAOTzol4XAAAohwAHgKQIcABIigAHgKQIcABIakE3B1u0aFE0Go1uDgkA6W3evPmPEdE3eXlXA7zRaGhkZKSbQwJAerZ/P9VyDqEAQFIEOAAkRYADQFIEOAAkRYADQFIEOAAk1TbAbX/T9jbb901Y9jLbP7f9cOv3AZ0tEwAwWZE98G9LOnXSsgFJmyLidZI2ta4DALqobYBHxC8l/XnS4lWSNrYub5R0Rr1lAQDaKXsM/JUR8bQktX6/YroVba+1PWJ7ZGxsrORwUmNgSI2BodL3B4DdTcffxIyI9RHRHxH9fX27nMoPACipbID/wfaBktT6va2+kgAARZQN8OslndO6fI6kH9dTDgCgqCIfI/y+pNskHWZ7q+3zJF0q6e22H5b09tZ1AEAXtf062Yh47zQ3ray5FgDALHAmJgAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFKVAtz2J23fb/s+29+3vbCuwgAAMysd4LYPkvQxSf0R8QZJe0g6s67CAAAzq3oIZYGkF9teIGlvSU9VLwkAUETpAI+IJyV9UdLjkp6W9GxE/GzyerbX2h6xPTI2Nla+UgDATqocQjlA0ipJSyW9StI+tt8/eb2IWB8R/RHR39fXV75SAMBOqhxCeZuk30XEWES8IOk6ScfXUxYAoJ0qAf64pGNt723bklZKGq2nLABAO1WOgd8h6RpJd0q6t/VY62uqCwDQxoIqd46Iz0n6XE21AABmgTMxASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkiLAASApAhwAkqoU4Lb3t32N7Qdtj9o+rq7CAAAzW1Dx/l+W9JOIWG17L0l711ATAKCA0gFu+6WSTpT0QUmKiOclPV9PWQCAdqocQnmNpDFJ37J9l+0NtvepqS4AQBtVAnyBpKMlfT0ijpL0d0kDk1eyvdb2iO2RsbGxCsPVb8XGFVqxcUWvywAwFwzu1/xJpEqAb5W0NSLuaF2/Rs1A30lErI+I/ojo7+vrqzAcAGCi0gEeEc9IesL2Ya1FKyU9UEtVAIC2qn4K5UJJV7Y+gfKopHOrlwQAKKJSgEfEFkn99ZQCAJgNzsQEgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKTSBnjZuSwbA0NqDAzVXA0AdF/aAAeA+Y4AB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASKpygNvew/Zdtm+ooyAAQDF17IF/XNJoDY8DAJiFSgFu+2BJ75S0oZ5yAABFVd0Dv1zSpyX9d7oVbK+1PWJ7ZGxsrOJwM7tszem6bM3pOy3bNHyoNg0fuuvKg/uVHmfFxhWlJ1VGdevOH9a684d7XQZ6ZOvALdo6cMsuyxffvKX7xfRY6QC3fbqkbRGxeab1ImJ9RPRHRH9fX1/Z4QAAk1TZA3+LpHfZfkzSVZJOsf29WqoCALRVOsAj4jMRcXBENCSdKWk4It5fW2UAgBnxOXAASGpBHQ8SEb+Q9Is6HgsAUAx74ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEuaXTZco0uW97rMgqZOKFyLyf3nY8TC8/0OhkcHNTg4ODUE2hP8TidUGTsQgb3qzTpdydNnLR8/DmfCxbfvEWNgSE1Boa6+vwR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEkR4ACQFAEOAEmVDnDbh9i+2fao7fttf7zOwgAAM1tQ4b7bJV0UEXfafomkzbZ/HhEP1FQbAGAGpffAI+LpiLizdfmvkkYlHVRXYQCAmVXZA9/BdkPSUZLumOK2tZLWStKSJUvqGG6H8bkFh09aN+Xtg4ODOuHEWoec1vhcfRf94IbC91mxcYXuPefeUuONLlsuTdP3VBoDQ5Kkxy59Z6nxpht7Vn2PzxM4+GwtY89k8c1bJEnPnPzGWY9R53NVl/HX+vIHR3cs2zpwiyTp4EtP6Ho942NvWLhJknTCid+VJK085be7rDs+h+vVl2zfqf5O2LHtFr6vOfbSJbWOPbnvXs/JWflNTNv7SrpW0ici4rnJt0fE+ojoj4j+vr6+qsMBAFoqBbjtPdUM7ysj4rp6SgIAFFHlUyiW9A1JoxHxpfpKAgAUUWUP/C2SzpZ0iu0trZ/TaqoLANBG6TcxI+JXklxjLQCAWeBMTABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIqpZJjbtqfGLcpdNPkDw+8agW/n/Z+CS3C3ddvbTRZcunnVBZkjYNHypJOsvXSpowwe6EHqaarHZKs+h7w8JNM04yKzUnmr36ku3Fxp5wH0m6eqYyW5O8Dg4O1jOxcGty2pkmQp7t5L6zfs6nGHt8Muc1Sy9uLpjihVXH5MhFnvOJdnnOa5hIety684f1r780J9/a0fcU4y/86ZOSJmy7GV6zEzUGhgpt7165bM3p0/Y9lYmTOUvF/85mgz1wAEiKAAeApAhwAEiKAAeApAhwAEiKAAeApAhwAEiKAAeApAhwAEiKAAeApAhwAEiKAAeApAhwAEiKAAeApAhwAEiKAAeApAhwAEiqUoDbPtX2Q7YfsT1QV1EAgPZKB7jtPSStk/QOSYdLeq/tw+sqDAAwsyp74G+S9EhEPBoRz0u6StKqesoCALTjiCh3R3u1pFMj4sOt62dLenNEXDBpvbWS1rauHibpoVkMs0jSH0sVmM986XW+9CnNn17nS59S73p9dUT0TV5YZVZ6T7Fsl38NImK9pPWlBrBHIqK/zH2zmS+9zpc+pfnT63zpU5p7vVY5hLJV0iETrh8s6alq5QAAiqoS4L+W9DrbS23vJelMSdfXUxYAoJ3Sh1AiYrvtCyT9VNIekr4ZEffXVllTqUMvSc2XXudLn9L86XW+9CnNsV5Lv4kJAOgtzsQEgKQIcABIak4EeLtT8t30ldbt99g+uhd1VlWgz2W2b7P9b9uf6kWNdSnQ61mtbXmP7VttH9mLOutQoNdVrT632B6x/dZe1FlV0a/OsH2M7f+0zhVJqcA2Pcn2s61tusX2Z3tRpyKipz9qvgH6W0mvkbSXpLslHT5pndMk3aTmZ8+PlXRHr+vuUJ+vkHSMpC9I+lSva+5wr8dLOqB1+R0Zt+kset1X/3+/6QhJD/a67k70OWG9YUk3Slrd67o7uE1PknRDr2udC3vgRU7JXyXpO9F0u6T9bR/Y7UIrattnRGyLiF9LeqEXBdaoSK+3RsRfWldvV/M8goyK9Pq3aP3VS9pHU5zwlkDRr864UNK1krZ1s7iapfmakLkQ4AdJemLC9a2tZbNdZ67bHXooara9nqfm/7AyKtSr7XfbflDSkKQPdam2OrXt0/ZBkt4t6You1tUJRV+/x9m+2/ZNtl/fndJ2NhcCvMgp+YVO25/jdoceiircq+2T1QzwiztaUecU/UqJH0bEMklnSPp8p4vqgCJ9Xi7p4oj4T+fL6agivd6p5veTHCnpq5J+1OmipjIXArzIKfm7w2n7u0MPRRXq1fYRkjZIWhURf+pSbXWb1XaNiF9KOtT2ok4XVrMiffZLusr2Y5JWS/qa7TO6Ul292vYaEc9FxN9al2+UtGcvtulcCPAip+RfL+kDrU+jHCvp2Yh4utuFVjSfvnqgba+2l0i6TtLZEfGbHtRYlyK9vta2W5ePVvONsWz/YLXtMyKWRkQjIhqSrpH00Yj4Udcrra7INl08YZu+Sc0s7fo2rfJthLWIaU7Jt31+6/Yr1HxH+zRJj0j6h6Rze1VvWUX6tL1Y0oikl0r6r+1PqPnu93O9qruMgtv0s5JeruZemiRtjzn0LW9FFez1PWrugLwg6Z+S1kx4UzOFgn3uFgr2ulrSR2xvV3ObntmLbcqp9ACQ1Fw4hAIAKIEAB4CkCHAASIoAB4CkCHAASIoAB4CkCHAASOp/dh1cpJs0QXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize_row(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:] = x[i,:]/np.sum(x[i,:])\n",
    "    return x\n",
    "def construct_static_graph(xs):\n",
    "    num_loc = xs.shape[0]\n",
    "    lamb = 0.5\n",
    "    ## 距离图\n",
    "    d = xs[:,:,0] \n",
    "    d = np.exp(-(d**2)/(np.std(d)**2))\n",
    "    \n",
    "    ## 人口\n",
    "    p = xs[:,:,1]\n",
    "    p = np.exp(-(p**2)/(np.std(p)**2))\n",
    "    \n",
    "    adj = lamb*d+(1-lamb)*p\n",
    "    np.fill_diagonal(adj,0)\n",
    "    plt.hist(adj)\n",
    "    mask = adj > 0.2\n",
    "    adj[mask] = 0\n",
    "    \n",
    "    return normalize_row(adj)+np.identity(num_loc)\n",
    "xs = features[\"xs\"]\n",
    "adj = construct_static_graph(xs)\n",
    "adj = spp.csr_matrix(adj)\n",
    "\n",
    "Gs = dgl.from_scipy(adj,'static').to(device)\n",
    "Gs.edata['static'] = Gs.edata['static'].type(torch.FloatTensor).to(device)\n",
    "print(Gs.edata['static'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c067943e-6379-46e7-a7e1-57265776f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(data): # (T,n,in_dim)\n",
    "    x, y = [],[]\n",
    "    # xi\n",
    "    l = data.shape[0]\n",
    "    for i in range(l-P-Q+1):\n",
    "        x.append(data[i:i+Q,:,:])\n",
    "        y.append(data[i+Q+P-1,:,0])\n",
    "    # print(np.array(x).shape,np.array(y).shape)\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "xi, xm = features[\"xi\"][:,:,2][:,:,np.newaxis], features[\"xm\"]    \n",
    "xi,xm = xi.transpose((1,0,2)),xm.transpose((1,0,2))\n",
    "data = np.concatenate((xi,xm),axis=2)\n",
    "\n",
    "train,val,test = data[:len_train],data[len_train:len_val],data[len_val:]\n",
    "\n",
    "train_x,train_y = splitDataset(train)\n",
    "val_x,val_y = splitDataset(val)\n",
    "test_x,test_y = splitDataset(test)\n",
    "\n",
    "train_x,train_y,val_x,val_y,test_x,test_y = torch.tensor(train_x).float().to(device),\\\n",
    "                                            torch.tensor(train_y).float().to(device),\\\n",
    "                                            torch.tensor(val_x).float().to(device),\\\n",
    "                                            torch.tensor(val_y).float().to(device),\\\n",
    "                                            torch.tensor(test_x).float().to(device),\\\n",
    "                                            torch.tensor(test_y).float().to(device)\n",
    "                                                         \n",
    "train_set = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "val_set = torch.utils.data.TensorDataset(val_x, val_y)\n",
    "test_set = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "train_iter = DataLoader(train_set,batch_size=20,shuffle=True,drop_last=False)\n",
    "val_iter = DataLoader(train_set,batch_size=20,shuffle=False,drop_last=False)\n",
    "test_iter = DataLoader(train_set,batch_size=20,shuffle=False,drop_last=False)\n",
    "# for x,y in train_iter:\n",
    "#     print(x.shape,y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0af54f9-8b4d-4b58-bb19-a3c9997fa136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mdl3(nn.Module):\n",
    "    \n",
    "    def series_similarity(a,b): #(b,n,T)\n",
    "        sim = torch.zeros(self.num_loc,self.num_loc).to(a.device)\n",
    "        for i in range(self.num_loc):\n",
    "            for j in range(i+1,self.num_loc):\n",
    "                sim[i][j] = F.cosine_similarity(a[i,:],b[j,:])\n",
    "                sim[j][i] = sim[i][j]\n",
    "        return sim\n",
    "        \n",
    "    def __init__(self,args):\n",
    "        super(mdl3,self).__init__()\n",
    "        self.hidS = args['hidS']\n",
    "        self.m = args['m']\n",
    "        self.hidC = args['hidC']\n",
    "        self.hidR = args['hidR']\n",
    "        self.Q = args['Q']\n",
    "        self.Ck = 3\n",
    "        self.w = args['w']\n",
    "        self.dropout = nn.Dropout(p = args['dropout'])\n",
    "        \n",
    "        self.norm = EdgeWeightNorm(norm='both')\n",
    "        self.GCN = GraphConv(self.Q, self.hidS, norm='none', weight=True, bias=True)\n",
    "        self.fc1 = nn.Linear(self.hidS,1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,self.hidC,kernel_size =(self.Ck,self.m)) # 在时间维度上卷积\n",
    "        self.GRU = nn.GRU(self.hidC,self.hidR,batch_first=True)\n",
    "        self.fc2 = nn.Linear(self.hidR,self.m)\n",
    "        \n",
    "        \n",
    "        # self.ar = nn.Linear(self.w,1)\n",
    "        \n",
    "    '''\n",
    "    x -> (batch_size,Q,n,in_dim)\n",
    "    Gs -> (n,n)\n",
    "    \n",
    "    #Gd -> (batch_size,n,n,in_dim) elsement-wise sum up - > (batch_size,n,n)\n",
    "    \n",
    "    Gs\n",
    "   \n",
    "    '''\n",
    "    def forward(self,Gs,x):\n",
    "        xi = x[:,:,:,0]\n",
    "        batch_size,T = x.shape[0],x.shape[1]\n",
    "        spat = torch.zeros(batch_size,self.m,self.hidS).to(x.device)\n",
    "        for b in range(batch_size):\n",
    "            norm_weights = Gs.edata['static']\n",
    "            feats = xi[b,:,:].permute(1,0)\n",
    "            spat[b,:,:] = self.GCN(Gs,feats,edge_weight=norm_weights)\n",
    "        spat = self.dropout(spat)\n",
    "        s = self.fc1(spat).squeeze()\n",
    "        \n",
    "\n",
    "        c = xi.view(-1, 1, self.Q, self.m)\n",
    "        c = F.relu(self.conv1(c))\n",
    "        c = self.dropout(c)\n",
    "        c = torch.squeeze(c, 3)\n",
    "        \n",
    "        r = c.permute( 0,2,1).contiguous()\n",
    "        # print(r.shape)\n",
    "        _,r = self.GRU(r)\n",
    "        r = self.dropout(torch.squeeze(r,0))\n",
    "        # print(r.shape)\n",
    "        res = self.fc2(r)\n",
    "        # print(res.shape)\n",
    "        \n",
    "\n",
    "        # a = xi[:,-self.w:,:].permute(0,2,1)\n",
    "        # a = self.ar(a).squeeze()\n",
    "        \n",
    "        return res+s\n",
    "        return res+a+s #(b,m)    \n",
    "        \n",
    "args = {'hidS':64,'m':xs.shape[0],'hidC':64,'hidR':64,'dropout':0.2,'Q':Q,'w':3}\n",
    "model = mdl3(args).to(device)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n",
    "early_stopping = EarlyStopping(save_path=save_path,patience=10, verbose=True)\n",
    "loss=nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd32591-e215-44aa-8be3-04b5274b6c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 1493.951773).  Saving model ...\n",
      "Validation loss decreased (1493.951773 --> 909.824065).  Saving model ...\n",
      "Validation loss decreased (909.824065 --> 836.119046).  Saving model ...\n",
      "Validation loss decreased (836.119046 --> 643.162448).  Saving model ...\n",
      "Validation loss decreased (643.162448 --> 594.188878).  Saving model ...\n",
      "Validation loss decreased (594.188878 --> 563.485498).  Saving model ...\n",
      "Validation loss decreased (563.485498 --> 530.061042).  Saving model ...\n",
      "Validation loss decreased (530.061042 --> 498.553042).  Saving model ...\n",
      "Validation loss decreased (498.553042 --> 483.696547).  Saving model ...\n",
      "Validation loss decreased (483.696547 --> 466.364868).  Saving model ...\n",
      "Validation loss decreased (466.364868 --> 438.823053).  Saving model ...\n",
      "Validation loss decreased (438.823053 --> 414.047040).  Saving model ...\n",
      "Validation loss decreased (414.047040 --> 395.820789).  Saving model ...\n",
      "Validation loss decreased (395.820789 --> 382.956960).  Saving model ...\n",
      "Validation loss decreased (382.956960 --> 373.552294).  Saving model ...\n",
      "Validation loss decreased (373.552294 --> 372.758510).  Saving model ...\n",
      "Validation loss decreased (372.758510 --> 363.111186).  Saving model ...\n",
      "Validation loss decreased (363.111186 --> 360.255142).  Saving model ...\n",
      "Validation loss decreased (360.255142 --> 357.044418).  Saving model ...\n",
      "Validation loss decreased (357.044418 --> 352.557662).  Saving model ...\n",
      "Validation loss decreased (352.557662 --> 352.065919).  Saving model ...\n",
      "Validation loss decreased (352.065919 --> 351.203311).  Saving model ...\n",
      "Validation loss decreased (351.203311 --> 347.907649).  Saving model ...\n",
      "Validation loss decreased (347.907649 --> 345.846730).  Saving model ...\n",
      "Validation loss decreased (345.846730 --> 344.493623).  Saving model ...\n",
      "Validation loss decreased (344.493623 --> 340.867728).  Saving model ...\n",
      "Validation loss decreased (340.867728 --> 334.217338).  Saving model ...\n",
      "Validation loss decreased (334.217338 --> 332.643682).  Saving model ...\n",
      "Validation loss decreased (332.643682 --> 332.638099).  Saving model ...\n",
      "Validation loss decreased (332.638099 --> 328.844008).  Saving model ...\n",
      "Validation loss decreased (328.844008 --> 324.240957).  Saving model ...\n",
      "Validation loss decreased (324.240957 --> 323.798287).  Saving model ...\n",
      "Validation loss decreased (323.798287 --> 321.098204).  Saving model ...\n",
      "Validation loss decreased (321.098204 --> 313.942718).  Saving model ...\n",
      "Validation loss decreased (313.942718 --> 311.153634).  Saving model ...\n",
      "Validation loss decreased (311.153634 --> 310.288549).  Saving model ...\n",
      "Validation loss decreased (310.288549 --> 307.708872).  Saving model ...\n",
      "Validation loss decreased (307.708872 --> 307.299585).  Saving model ...\n",
      "Validation loss decreased (307.299585 --> 302.422051).  Saving model ...\n",
      "Validation loss decreased (302.422051 --> 301.301137).  Saving model ...\n",
      "Validation loss decreased (301.301137 --> 297.019907).  Saving model ...\n",
      "Validation loss decreased (297.019907 --> 293.141874).  Saving model ...\n",
      "Validation loss decreased (293.141874 --> 291.960407).  Saving model ...\n",
      "Validation loss decreased (291.960407 --> 288.998822).  Saving model ...\n",
      "Validation loss decreased (288.998822 --> 288.691939).  Saving model ...\n",
      "Validation loss decreased (288.691939 --> 284.894699).  Saving model ...\n",
      "Validation loss decreased (284.894699 --> 281.915471).  Saving model ...\n",
      "Validation loss decreased (281.915471 --> 279.896239).  Saving model ...\n",
      "Validation loss decreased (279.896239 --> 278.684315).  Saving model ...\n",
      "Validation loss decreased (278.684315 --> 276.991751).  Saving model ...\n",
      "Validation loss decreased (276.991751 --> 274.370248).  Saving model ...\n",
      "Validation loss decreased (274.370248 --> 274.125519).  Saving model ...\n",
      "Validation loss decreased (274.125519 --> 273.014109).  Saving model ...\n",
      "Validation loss decreased (273.014109 --> 270.698145).  Saving model ...\n",
      "Validation loss decreased (270.698145 --> 270.339185).  Saving model ...\n",
      "Validation loss decreased (270.339185 --> 268.411618).  Saving model ...\n",
      "Validation loss decreased (268.411618 --> 267.243590).  Saving model ...\n",
      "Validation loss decreased (267.243590 --> 263.206700).  Saving model ...\n",
      "Validation loss decreased (263.206700 --> 260.846791).  Saving model ...\n",
      "Validation loss decreased (260.846791 --> 258.917276).  Saving model ...\n",
      "Validation loss decreased (258.917276 --> 258.451828).  Saving model ...\n",
      "Validation loss decreased (258.451828 --> 258.319288).  Saving model ...\n",
      "Validation loss decreased (258.319288 --> 253.413263).  Saving model ...\n",
      "Validation loss decreased (253.413263 --> 251.264175).  Saving model ...\n",
      "Validation loss decreased (251.264175 --> 249.626120).  Saving model ...\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "min_val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    l_sum, n = 0.0,0\n",
    "    model.train()\n",
    "    for x,y in train_iter:\n",
    "        y_pred = model(Gs,x).view(-1)\n",
    "        l = loss(y_pred,y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        l_sum += l.item()*y.shape[0]\n",
    "        n += y.shape[0]\n",
    "    val_loss = evaluate_model(model,val_iter,scaler,method=\"mdl3\",isprint=False,retMetrics=\"MAE\",graph = Gs)\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print (\"early stopping\")\n",
    "        break\n",
    "    # if val_loss < min_val_loss:\n",
    "    #     min_val_loss = val_loss\n",
    "    #     torch.save(model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d92ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========mdl3=========\n",
      "RMSE\t 407.940432\n",
      "MAE\t 249.626120\n",
      "MAPE\t 22.401349\n",
      "SMAPE\t 24.026894\n",
      "Corr\t 0.953204\n",
      "CCC\t 0.949384\n",
      "<utils.Evaluation_metrics object at 0x7faa88026e80>\n"
     ]
    }
   ],
   "source": [
    "best_model = mdl3(args).to(device)\n",
    "best_model.load_state_dict(torch.load(save_path))\n",
    "y_true,y_pred = evaluate_model(best_model,test_iter,scaler,method=\"mdl3\",isprint=True,retRes=True,graph=Gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd17007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
