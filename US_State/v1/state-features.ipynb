{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae9f643-609d-4460-b2eb-747bf1a58083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "\n",
    "len_train =80 \n",
    "'''\n",
    "Min-Max Scaler\n",
    "展平所有特征，进行放缩\n",
    "'''\n",
    "class MyMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.xmin,self.xmax = None,None\n",
    "    def fit_transform(self,train):\n",
    "        self.xmin,self.xmax = np.min(train),np.max(train)\n",
    "        return self.transform(train)\n",
    "    def transform(self,x):\n",
    "        return (x-self.xmin)/(self.xmax-self.xmin)\n",
    "    def inverse_transform(self,t):\n",
    "        return t*(self.xmax-self.xmin)+self.xmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56dab3-fdf8-4c67-8fe3-87f7fd0f0923",
   "metadata": {},
   "source": [
    "## 预处理\n",
    "+ 对齐fips\n",
    "+ 检查缺失值\n",
    "+ 检查条数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5c069e-d7e7-4c28-83a8-f75e09fb8694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1694, 4)\n",
      "(14, 6)\n",
      "(1680, 8)\n",
      "(1680, 4)\n"
     ]
    }
   ],
   "source": [
    "common = None\n",
    "for fn in ['cases.csv','static.csv','mobility.csv','range.csv']:\n",
    "    df = pd.read_csv(fn)\n",
    "    if common is None:\n",
    "        common = set(df['fips'].unique())\n",
    "    else:\n",
    "        common = common & set(df['fips'].unique())\n",
    "for fn in ['cases.csv','static.csv','mobility.csv','range.csv']:\n",
    "    df = pd.read_csv(fn)\n",
    "    df = df[df.fips.isin(common)]\n",
    "    print(df.shape)\n",
    "    df.to_csv(fn,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfb538-09d9-41f7-8c66-8dc8d387bcba",
   "metadata": {},
   "source": [
    "## Static features\n",
    "+ (14,14,2) 第1张图表示距离，第2张图表示人口特征相似性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e6bc8a-b356-4050-bc1e-9fde45dcc985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('static.csv')\n",
    "df.sort_values(by=['fips'],inplace=True)\n",
    "n = df.shape[0]\n",
    "xs = np.zeros((n,n,2))\n",
    "lat,long = df['lat'].values,df['long'].values\n",
    "scaler = MinMaxScaler()\n",
    "pop = scaler.fit_transform(df[['pop_density', 'tot_pop']].values)\n",
    "print(pop.shape)\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "\n",
    "        xs[i,j,0] = haversine((lat[i],long[i]),(lat[j],long[j]),'km')\n",
    "        xs[j,i,0] = xs[i,j,0]\n",
    "\n",
    "        xs[i,j,1] = 1 - spatial.distance.cosine(pop[i,:], pop[j,:])\n",
    "        # print(i,j,result)\n",
    "        xs[j,i,1] = xs[i,j,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251ed3f-c4d5-4b88-80f8-5d72485c820d",
   "metadata": {},
   "source": [
    "## 感染人数相关特征\n",
    "+ cases比实际天数提前一天，为了确定新增人数\n",
    "+ (14,120,6) = (state,time_length,features_dim)\n",
    "+ 累积确诊、累积死亡、新增确诊、新增死亡、新增确诊/累积确诊、新增死亡/累积死亡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1104372b-a5bb-4ce8-9816-fa3b0915971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cases.csv')\n",
    "df.sort_values(by=['fips','date'],inplace=True)\n",
    "fips = df['fips'].unique()\n",
    "n,l = len(fips), int(df.shape[0]/len(fips))\n",
    "xi = np.zeros((n,l,6))\n",
    "\n",
    "### Acc_Cases\n",
    "for i,fip in enumerate(fips):\n",
    "    xi[i,:,0] = df[df.fips==fip]['cases'].values\n",
    "    xi[i,:,1] = df[df.fips==fip]['deaths'].values\n",
    "    \n",
    "\n",
    "xi[:,1:,2] = xi[:,1:,0]-xi[:,:-1,0]\n",
    "\n",
    "xi[:,1:,3] = xi[:,1:,1]-xi[:,:-1,1]\n",
    "\n",
    "xi[:,:,4] = xi[:,:,2] / xi[:,:,0]\n",
    "\n",
    "mask = (xi[:,:,1]!=0)\n",
    "xi[mask,5] = xi[mask,3] / xi[mask,1]\n",
    "\n",
    "xi = xi[:,1:,:]\n",
    "\n",
    "### 保存xi[:,:,2]的scaler\n",
    "for i in range(6):\n",
    "    scaler = MyMinMaxScaler()\n",
    "    xi[:,:len_train,i] = scaler.fit_transform(xi[:,:len_train,i])\n",
    "    xi[:,len_train:,i] = scaler.transform(xi[:,len_train:,i])\n",
    "    if i==2:\n",
    "        f = open('scaler.pickle','wb')\n",
    "        pickle.dump(scaler, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f36c73-f034-48f3-9dd8-a0b5ebdb13bd",
   "metadata": {},
   "source": [
    "## mobilty and movement range\n",
    "+ (14,120,8)\n",
    "+ 6 mobility+2 range\n",
    "+ 现在是对同一特征下的所有站点的所有时间点进行归一化，后面考虑针对不同站点归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813328d8-e633-43f7-a4dc-8fb4a4db1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mob = pd.read_csv('mobility.csv')\n",
    "mob.sort_values(by=['fips','date'],inplace=True)\n",
    "move = pd.read_csv('range.csv')\n",
    "move.sort_values(by=['fips','date'],inplace=True)\n",
    "\n",
    "fips = mob['fips'].unique()\n",
    "num_loc = len(fips)\n",
    "xm = np.zeros((num_loc,int(mob.shape[0]/len(fips)),8)) # (n,T,8)\n",
    "\n",
    "for i,fip in enumerate(fips):\n",
    "    xm[i,:,:6] = mob[mob.fips==fip][['f1','f2','f3','f4','f5','f6']].values\n",
    "    xm[i,:,6:] = move[move.fips==fip][['f1','f2']].values\n",
    "\n",
    "for i in range(8):\n",
    "    scaler = MyMinMaxScaler()\n",
    "    xm[:,:len_train,i] = scaler.fit_transform(xm[:,:len_train,i])\n",
    "    xm[:,len_train:,i] = scaler.transform(xm[:,len_train:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dfaa7-bf62-4253-8afc-5b38de7d9969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bacc973d-c7e2-489f-a8d4-11c28189b11c",
   "metadata": {},
   "source": [
    "## 封装成pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1c4293-5c65-45f1-b062-0d1d2689afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'xs':xs,'xm':xm,'xi':xi}\n",
    "f = open('features.pickle','wb')\n",
    "pickle.dump(features, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a53a2e-4aa7-4ba6-a2b0-c38018961dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
